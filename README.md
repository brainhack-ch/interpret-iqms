# Interpreting the IQMs of MRIQC

In this project we want to improve the interpretability of the Image Quality Metrics (IQMs) generated by MRIQC.

**What is MRIQC?**

MRIQC is an open-source tool to assess the quality of structural and functional MRI images. It generates visual reports for every scan, as well as a number of IQMs which are collected in a group-level report.

**What are IQMs?**

Image Quality Metrics (IQMs) are automatically generated metrics that reflect different aspects of the quality of an MR image. In the [MRIQC paper](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0184661#pone-0184661-t002) on table 2 you can find an overview of the IQMs and what they are measuring.

**What data do we use?**

We will use the [Movement-Related Artifacts (MR-ART)](https://www.nature.com/articles/s41597-022-01694-8) dataset. It contains the T1-weighted images of 148 healthy subjects. For every subject, there are images in three conditions:

1. no head movement
2. little head movement
3. much head movement

**How are we approaching the problem?**

We are using two different approaches to this problem.

1. We use dimensionality reduction techniques such as PCA, ICA, or Factor Analysis to find summary dimensions that combine the metrics with potentially redundant information.

2. We use machine learning, in particular supervised learning, to predict the quality ratings and/or the motion condition of the images from the IQMs.

We will combine what we learned with both approaches in a dedicated notebook.

**What will be the output?**

We will combine what we learned in a notebook that will be part of the [Nipreps QC book](https://www.nipreps.org/qc-book/welcome.html). We need to export our notebook that summarizes the approaches that worked in markdown and create a pull request to add it as a chapter in the [repo for the QC book](https://github.com/nipreps/qc-book).
