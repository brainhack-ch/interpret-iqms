{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability of the Image Quality Metrics (IQMs) of MRIQC\n",
    "\n",
    "MRIQC is a powerful tool to assess the quality of MR images in a research study. In addition to a visual report, a number of image quality metrics (IQMs) is generated. However, there is a large number of these metrics and it is not immediately obvious which IQM a researcher should pay most attention to when deciding over the quality of a given image.\n",
    "\n",
    "In this notebook, we will explore these issues in the MR-ART dataset, to provide researchers guidance in interpreting the IQMs from MRIQC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the data. The [Movement-Related Artifacts (MR-ART)](https://www.nature.com/articles/s41597-022-01694-8) dataset contains the T1-weighted images of 148 healthy subjects. Each subject has been acquired under three motion conditions:\n",
    "\n",
    "1. no head movement\n",
    "2. little head movement\n",
    "3. much head movement\n",
    "\n",
    "The motion was artifically induced by giving the subjects cues when to node their head.\n",
    "\n",
    "The images were given to two expert raters, who rated the images in their quality, with ratings\n",
    "\n",
    "1. good quality\n",
    "2. medium quality\n",
    "3. bad quality.\n",
    "\n",
    "What we are interested in here are the IQMs and the ratings scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to the data, adjust to where you saved yours\n",
    "path_data = os.path.abspath(\"../../data/\")\n",
    "# import IQMs\n",
    "iqms = pd.read_csv(os.path.join(path_data, \"group_T1w.tsv\"), sep=\"\\t\")\n",
    "# import rating scores\n",
    "scores = pd.read_csv(os.path.join(path_data, \"scores.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_condition_column(scores):\n",
    "    stand = scores[\"bids_name\"].str.contains(\"standard\")\n",
    "    hm1 = scores[\"bids_name\"].str.contains(\"motion1\")\n",
    "    hm2 = scores[\"bids_name\"].str.contains(\"motion2\")\n",
    "    conditions = [\n",
    "        (stand == True),\n",
    "        (hm1 == True),\n",
    "        (hm2 == True)]\n",
    "    choices = [1, 2, 3]\n",
    "    scores['condition'] = np.select(conditions, choices)\n",
    "    print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('bh22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44c0fd920f5116b8d7b777cfa2ba8fdb141ca110dbe727c0c86f35c9859cc955"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
